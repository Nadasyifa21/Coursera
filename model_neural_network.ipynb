{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1yqc0Wlae4UXgQDqIE7yi6mHFIuDPha-f",
      "authorship_tag": "ABX9TyMUadhzdFXNQfbXPglFJaY0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nadasyifa21/Coursera/blob/main/model_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2wISh_WKKKk"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "Q2b5iD0XLJo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/datagenerated.csv', sep=\",\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "2q0WJdTCLOuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "vtl2aTRYLeLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "anbYHZkxLiy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Fxb5JMj7Lnb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "aPXcCzSxLr29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Miss Valuse\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "jna9v2CzLy3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Duplicated value\n",
        "data_dup = df.duplicated().any()\n",
        "data_dup"
      ],
      "metadata": {
        "id": "hR8JSQfQL2s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "ZyGX18pjL6Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dup = df.duplicated().any()\n",
        "data_dup"
      ],
      "metadata": {
        "id": "MzCCBr0KL-f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ca_val=[]\n",
        "co_val=[]\n",
        "\n",
        "for column in df.columns:\n",
        "    if df[column].nunique() <=10:\n",
        "        ca_val.append(column)\n",
        "    else:\n",
        "        co_val.append(column)"
      ],
      "metadata": {
        "id": "b1ydMh1rMFkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorical Data\n",
        "ca_val"
      ],
      "metadata": {
        "id": "A_g96p6nMJ6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Risk'].unique()"
      ],
      "metadata": {
        "id": "oiPAdqo1MNxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "co_val"
      ],
      "metadata": {
        "id": "ZqdHoiZIMR4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Age'].unique()"
      ],
      "metadata": {
        "id": "dtTiMGAVMVh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Risk'].unique()"
      ],
      "metadata": {
        "id": "oGKB61wJMZ_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Risk = {\n",
        "    \"Normal\": 0,\n",
        "    \"High\": 1,\n",
        "}\n",
        "\n",
        "# apply using map\n",
        "df[\"Risk\"] = df[\"Risk\"].map(Risk).astype(float)\n",
        "df"
      ],
      "metadata": {
        "id": "TMz_T9kQMdsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Risk'].value_counts()"
      ],
      "metadata": {
        "id": "Gs3UPEN4Mldx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "8mdhLLaoMqG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cor = df.corr()\n",
        "plt.figure(figsize = (10,6))\n",
        "sns.heatmap(cor, annot = True)"
      ],
      "metadata": {
        "id": "tafxMo-NMuA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "df.hist(bins=50, figsize=(20, 15))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4xAwZkN_My7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='Risk', data=df, palette='viridis')"
      ],
      "metadata": {
        "id": "Gr11u-hMM38Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Risk',axis=1)\n",
        "y = df['Risk']"
      ],
      "metadata": {
        "id": "vbsH5DXQM83X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "o6TO1drMNAZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "oEGPZJvnNIsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting The Dataset\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,\n",
        "                                               random_state=42)\n",
        "y_test"
      ],
      "metadata": {
        "id": "Sh5kzXtHNMwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training Shape x:',X_train.shape)\n",
        "print(f'Testing Shape x:',X_test.shape)\n",
        "print('*****___________*****___________*****')\n",
        "print(f'Training Shape y:',X.shape)\n",
        "print(f'Testing Shape y:',y.shape)"
      ],
      "metadata": {
        "id": "5SF7dcC4NQuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalisasi data dengan StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "X_train = ss.fit_transform(X_train)\n",
        "X_test= ss.transform(X_test)"
      ],
      "metadata": {
        "id": "gliz3t3HNUdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a neural network model\n",
        "model = Sequential()\n",
        "\n",
        "# Add input layer and hidden layers\n",
        "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "train_accuracy = model.evaluate(X_train, y_train, verbose=0)[1]\n",
        "test_accuracy = model.evaluate(X_test, y_test, verbose=0)[1]\n",
        "\n",
        "print(\"Train accuracy:\", train_accuracy)\n",
        "print(\"Test accuracy:\", test_accuracy)\n",
        "\n",
        "# Predictions\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Confusion Matrix and other metrics\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix:', cm)\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred) * 100, '%')\n",
        "print('Classification Report:\\n', classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "IhMnX_iANZNu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}